services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # CẤU HÌNH SỬA LỖI KAFKA NETWORK CHO DOCKER
      KAFKA_LISTENERS: PLAINTEXT_INTERNAL://0.0.0.0:29092,PLAINTEXT_EXTERNAL://0.0.0.0:9092
      # ĐÃ SỬA: Thay địa chỉ không phân giải (2061215) bằng tên dịch vụ (kafka)
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT_INTERNAL://kafka:29092,PLAINTEXT_EXTERNAL://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL # Bắt buộc phải sử dụng internal listener name
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # DỊCH VỤ MỚI: Đảm bảo Topic được tạo thành công
  kafka-topic-initializer:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      - kafka
    # GIỮ NGUYÊN: Vẫn dùng kiểm tra động vì image này có công cụ Kafka
    command: |
      sh -c "
        echo 'INIT: Dynamically waiting for Kafka Broker to be fully registered...';
        while ! /bin/kafka-broker-api-versions --bootstrap-server kafka:29092; do 
          sleep 5; 
        done;
        
        echo 'INIT: Kafka Broker is RESPONSIVE. Creating topic...';

        # Sửa lỗi cú pháp multi-line
        /bin/kafka-topics --bootstrap-server kafka:29092 --topic stock_data --create --partitions 1 --replication-factor 1 --if-not-exists;
        
        echo 'INIT: Topic stock_data is ready. Exiting initializer.'
      "
  
  # BỔ SUNG: Consumer kiểm tra để xác nhận dữ liệu đang được đẩy vào Kafka
  kafka-test-consumer:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      - kafka-topic-initializer
    # GIỮ NGUYÊN: Vẫn dùng kiểm tra động vì image này có công cụ Kafka
    command: |
      sh -c "
        echo 'TEST: Dynamically waiting for Kafka Broker to be fully registered...';
        while ! /bin/kafka-broker-api-versions --bootstrap-server kafka:29092; do 
          sleep 5; 
        done;
        
        echo 'TEST: Kafka Broker is RESPONSIVE. Waiting 10s for producer to send data...';
        sleep 10;
        
        echo 'TEST: Starting test consumer to verify data flow...';
        # ĐÃ SỬA: Đặt lệnh consumer vào MỘT DÒNG logic
        /bin/kafka-console-consumer --bootstrap-server kafka:29092 --topic stock_data --from-beginning --max-messages 10 --timeout-ms 20000;
        echo 'TEST: Test consumer finished.';
      "

  data-ingestion:
    build:
      context: .
      dockerfile: Dockerfile.data-ingestion
    depends_on:
      - kafka-topic-initializer # Bây giờ phụ thuộc vào topic đã được tạo
    volumes:
      - ./src:/app/src
    # ĐÃ SỬA: Cập nhật tên file thành stock_api_consumer.py
    command: |
      sh -c "
        echo 'PRODUCER: Waiting 15 seconds for Kafka and Topic Initializer to complete...';
        sleep 15;
        echo 'PRODUCER: Kafka Broker is assumed ready. Starting producer...';
        
        # ĐÃ SỬA: Trỏ đúng vào tên file mới
        python /app/src/data_ingestion/stock_api_consumer.py
      "

  mongodb:
    image: mongo:6.0
    container_name: mongodb_container
    ports:
      - "27017:27017"
    volumes:
      - ./data/mongo:/data/db

  spark-processor:
    image: apache/spark:3.5.1-scala2.12-java17-python3-r-ubuntu
    user: root
    depends_on:
      - kafka-topic-initializer 
      - mongodb
    volumes:
      - ./src:/app/src
      - ./checkpoint:/app/checkpoint
    working_dir: /app
    environment: 
      SPARK_LOG_LEVEL: WARN
    # SỬA Ở ĐÂY: Đưa toàn bộ lệnh spark-submit về 1 dòng dài
    command: >
      sh -c "
        echo 'SPARK: Waiting 20 seconds for ecosystem...';
        sleep 20;
        echo 'SPARK: Submitting Job...';
        /opt/spark/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.mongodb.spark:mongo-spark-connector_2.12:10.3.0 src/feature_engineering/pyspark_processor.py
      "